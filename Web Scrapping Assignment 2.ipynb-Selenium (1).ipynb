{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import  NoSuchElementException\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Chaitra\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. First get the webpage https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering details in search criteria for designations\n",
    "search_job=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_job.send_keys('Data Analyst')\n",
    "\n",
    "#Entering deatils in loaction field\n",
    "search_location=driver.find_element_by_id('qsb-location-sugg')\n",
    "search_location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Then click the search button¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on search button\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Then scrape the data for the first 10 jobs results you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create empty list in which we will update the required data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting all the tages with the job titles.\n",
    "\n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title_tags:\n",
    "    job_title.append(i.text)\n",
    "    Job=job_title[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist / Data Analyst -Business Analyst',\n",
       " 'Network Design & Data Analyst',\n",
       " 'Consultant - Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'FTE - Regional BI - Functional Data Analyst',\n",
       " 'Deputy Manager - Data Analyst',\n",
       " 'Data Analyst CX',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Security Specialist - CS Awareness & Data Analyst']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Davangere, Bangalore/Bengaluru',\n",
       " 'Davangere, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting all the tages with the job location.\n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags:\n",
    "    job_location.append(i.text)\n",
    "    loc=job_location[:10]\n",
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inflexion Analytix Private Limited',\n",
       " 'Dell International Services India Private Limited',\n",
       " 'Flipkart Internet Private Limited',\n",
       " 'Siemens Limited',\n",
       " 'Bright Money',\n",
       " 'Schneider Electric India Pvt. Ltd.',\n",
       " 'Schneider Electric India Pvt. Ltd.',\n",
       " 'Philips India Limited',\n",
       " 'Flipkart Internet Private Limited',\n",
       " 'Cognizant Technology Solutions India Pvt Ltd']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting all the tages with the company names.\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags:\n",
    "    company_name.append(i.text)\n",
    "    com=company_name[:10]\n",
    "com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-3 Yrs',\n",
       " '0-2 Yrs',\n",
       " '0-2 Yrs',\n",
       " '0-5 Yrs',\n",
       " '0-2 Yrs',\n",
       " '5-8 Yrs',\n",
       " '3-6 Yrs',\n",
       " '6-10 Yrs',\n",
       " '4-5 Yrs',\n",
       " '4-7 Yrs']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting all the tages with the experince required.\n",
    "exp_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "for i in exp_tags:\n",
    "    experience_required.append(i.text)\n",
    "    exp=experience_required[:10]\n",
    "exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Finally create a dataframe of the scraped data.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Network Design &amp; Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Dell International Services India Private Limited</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Consultant - Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Siemens Limited</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Bright Money</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FTE - Regional BI - Functional Data Analyst</td>\n",
       "      <td>Davangere, Bangalore/Bengaluru</td>\n",
       "      <td>Schneider Electric India Pvt. Ltd.</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Deputy Manager - Data Analyst</td>\n",
       "      <td>Davangere, Bangalore/Bengaluru</td>\n",
       "      <td>Schneider Electric India Pvt. Ltd.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst CX</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>4-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Security Specialist - CS Awareness &amp; Da...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Cognizant Technology Solutions India Pvt Ltd</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Job  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                      Network Design & Data Analyst   \n",
       "2                          Consultant - Data Analyst   \n",
       "3                                       Data Analyst   \n",
       "4                                       Data Analyst   \n",
       "5        FTE - Regional BI - Functional Data Analyst   \n",
       "6                      Deputy Manager - Data Analyst   \n",
       "7                                    Data Analyst CX   \n",
       "8                                Senior Data Analyst   \n",
       "9  Senior Security Specialist - CS Awareness & Da...   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                     Davangere, Bangalore/Bengaluru   \n",
       "6                     Davangere, Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                             Company Experience Required  \n",
       "0                 Inflexion Analytix Private Limited             0-3 Yrs  \n",
       "1  Dell International Services India Private Limited             0-2 Yrs  \n",
       "2                  Flipkart Internet Private Limited             0-2 Yrs  \n",
       "3                                    Siemens Limited             0-5 Yrs  \n",
       "4                                       Bright Money             0-2 Yrs  \n",
       "5                 Schneider Electric India Pvt. Ltd.             5-8 Yrs  \n",
       "6                 Schneider Electric India Pvt. Ltd.             3-6 Yrs  \n",
       "7                              Philips India Limited            6-10 Yrs  \n",
       "8                  Flipkart Internet Private Limited             4-5 Yrs  \n",
       "9       Cognizant Technology Solutions India Pvt Ltd             4-7 Yrs  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_Analyst={'Job':Job,'Location':loc,\n",
    "              'Company':com,'Experience Required':exp}\n",
    "Data_Analyst=pd.DataFrame(data=Data_Analyst)\n",
    "Data_Analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. First get the webpage https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering details in search criteria for designations\n",
    "search_job=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_job.send_keys('Data Scientist')\n",
    "\n",
    "#Entering deatils in loaction field\n",
    "search_location=driver.find_element_by_id('qsb-location-sugg')\n",
    "search_location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Then click the search button¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on search button\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Then scrape the data for the first 10 jobs results you get.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create empty list in which we will update the required data\n",
    "job=[]\n",
    "loc=[]\n",
    "comp=[]\n",
    "desc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist / Data Analyst -Business Analyst',\n",
       " 'Sr Data Scientist',\n",
       " 'Sr Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Lead Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior/Lead Data Scientist - Machine Learning/Deep Learning',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Lead Data Scientist - Machine Learning/ Data Mining']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting all the tages with the job titles.\n",
    "\n",
    "title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title:\n",
    "    job.append(i.text)\n",
    "    job=job[:10]\n",
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location=driver.find_element_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "location.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru(JP Nagar)',\n",
       " 'Bangalore/Bengaluru(Dairy Circle)',\n",
       " 'Bangalore/Bengaluru(Banashankari Stage II)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Chennai, Bangalore/Bengaluru, Vadodara',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting all the tages with the job location.\n",
    "\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "for i in locations:\n",
    "    loc.append(i.text)\n",
    "loc=loc[:10]\n",
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inflexion Analytix Private Limited',\n",
       " 'Baker Hughes Incorporated',\n",
       " 'Baker Hughes - The Network',\n",
       " 'Confidential',\n",
       " 'ALTEN CALSOFT LABS (INDIA) PRIVATE LIMITED',\n",
       " 'Pegasus Knowledge Solutions India Private Limited',\n",
       " 'Squareroot Consulting Pvt Ltd.',\n",
       " 'Fractal Analytics',\n",
       " 'Nielsen',\n",
       " 'Wrackle Technologies Pvt Ltd']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting all the tages with the company names.\n",
    "company=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company:\n",
    "    comp.append(i.text)\n",
    "    \n",
    "comp=comp[:10]\n",
    "comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 Please note that you have to scrape full job description. For that you may have to open each job separately as shown below¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Job description\\n\\nJob Role: Data Scientist/Data Analyst /Business Analyst\\n\\nLocation: Chennai/Bangalore/Hyderabad\\n\\nGreetings from CAIA - Center for Artificial Intelligence & Advanced Analytics\\n43% of companies experienced a high deficit of skilled resources with Advanced Analytical skills and AI implementing capabilities in the year 2020. CAIA gives you a great opportunity to enter the world of future technologies and Innovations- Data Science, Analytics, AI, Data Visualization, and Cloud Computing.\\n\\nWhile 2020 was a year like no other, we are living in an interesting times where data is reshaping the world, and businesses are rapidly adopting technology to gain an edge over others. Hence, there's a substantial increase in demand for technology professionals who can implement systems in data science, machine learning, and AI in Tier 1 and Tier 2 organizations working closely with us.\\n\\nTo help you build a sustainable career we would like you to utilize data, software and Analytical approaches in Data Science and AI to upskill and get recruited into an organization appreciating your skilling journey.\\nApplications invited from all Freshers and experienced candidates (0-3 yrs) aspiring to make a career in Artificial Intelligence and Advanced Analytics and Data Science.\\nIf you wish to make a shift in your career or undergo a career transition, upskilling is essential since it allows you to learn more about the domain and acquire the required skills.\\n\\nCall to schedule interview Monday -Saturday from 10:00 am to 7 Pm\\n\\nKoodesh B- +91 73395 11107\\nManigandan B - +91 93444 57360\\n\\nEmail :\\n\\ncareerguidance.koodes@centerforaia.com\\nmanigandan@centerforaia.com\\n\\nWhat is needed from you?\\nFreshers who wish to start their career in Analytics and AI and professionals who wish to\\nupskill or change their domain to analytics and emerging technologies are free to apply.\\nEducational background in any one of the following- BE/B.Tech, ME/M Tech, MSc, BSc/MSc Math's and Statistics, B Com, BCA, BSc CS, BSC IT, MSC IT, MCA\\nSkills relating to Mathematics/Statistics.\\nNatural passion towards numbers, business, coding, Analytics, and Artificial Intelligence, Machine Learning, visualization\\nGood verbal and written communication skills\\nAbility to understand domains in businesses across various sectors\\n\\nSelection procedure includes\\nAptitude Test & Communication Exam - Online / Offline\\nSQL/Python test - Online / Offline\\nCandidates who clear the above will have one-one discussions with our Career Guidance Manager for further evaluation and processing of your Resume.\\n\\nAll the Shortlisted candidates will be eligible to continue the corporate training with CAIA\\nWhat you can expect from us?\\n\\nYou will get trained on the following modules for a period of 12-14 weeks:\\nSQL & PLSQL\\nData Wrangling using Python\\nData Visualization Using Power-BI\\nStatistics for Machine Learning\\nArtificial Intelligence, Data Interpretation\\nSupervised & Unsupervised Learning,\\nNLP & Deep Learning\\nCloud Data Lake\\nBusiness intelligence & Data Visualization\\nSimulation Projects\\nExpected Outcome?\\n\\nAt the end of the Training you are expected to be well versed with the following:\\nAnalysis of large and complex data sets from multiple sources\\nDevelopment and evaluation of data analytics models, algorithms, and solutions\\nUnderstanding/implementation of ML algorithms, performance tuning, and reporting\\nImplementation of algorithms to mine targeted data and the ability to convert data into a business story\\nTranslation of business requirements into technical requirements; Data extraction, preparation, and transformation\\nIdentification, development, and implementation of statistical techniques and algorithms that address business challenges and adds value to the organization\\nRequirement Analysis and communication of findings in the form of a meaningful story with the stakeholders\\nFinding analytical solutions to abstract business issues.\\nApply objective analysis of facts before coming to a conclusion\",\n",
       " 'As as Senior Data Scientist, you will work in teams addressing statistical, machine learning and data understanding problems in a commercial technology and consultancy development environment. In this role, you will contribute to the development and deployment of modern machine learning, operational research, semantic analysis, and statistical methods for finding structure in large data sets.\\nAs a Sr Data Scientist, you will be responsible for:\\nDesigning and develop machine learning algorithms, software utilities, tools, data sets, and experiments to build AI models.\\nBuilding solutions and delivering code from proof of concept to production-level maturity following agile development principles.\\nBreaking down and understanding complex business problems, defining a solution, and implementing it using advanced quantitative methods.\\nKeeping up to date with state-of-the-art machine learning literature and industry best practices for large-scale robust algorithm development.\\nDocumenting developments and results as needed for documentation, publications, patent submissions, and internal or external presentations.\\nCollaborating with cross-functional teams across multiple offices and regions. Also, Work alongside software developers and software engineers to translate algorithms into commercially viable products and services.\\nUnit-Testing for production quality code development and supporting end-to-end testing of delivered software components.\\nWorking in technical teams in development, deployment, and application of applied analytics, predictive analytics, and prescriptive analytics.\\nFuel your passion, To be successful in this role you will:\\nHave bachelors in Computer Science or STEM Majors (Science, Technology, Engineering and Math). A minimum 4 yrs of professional experience.\\nHave knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, and proper usage, etc.) and experience with applications.\\nExperience in Machine Learning/AI techniques including Deep learning (RNN, CNN, GAN, etc.), Support Vector Machines; Regularization Techniques; Boosting, Random Forests, Ensemble Methods, image/video/audio processing, Bayesian statistics, and time series modelling.\\nHave extensive applied experience with Reinforcement Learning is desired.\\nHave experience in developing and deploying machine learning solutions in cloud environments like AWS, Azure, and GCP.\\nHave developed containerized solutions (Docker, Mesos, etc.).\\nHave solid programming skills for data sciences and numerical computing: Python, R, and SQL and ability to work with a variety of deep learning frameworks including TensorFlow, Keras, Caffe, etc.\\nHave hands-on skills in sourcing, manipulating, and analysing large volumes of data including SQL and NoSQL databases.',\n",
       " 'As as Senior Data Scientist, you will work in teams addressing statistical, machine learning and data understanding problems in a commercial technology and consultancy development environment. In this role, you will contribute to the development and deployment of modern machine learning, operational research, semantic analysis, and statistical methods for finding structure in large data sets.\\nAs a Sr Data Scientist, you will be responsible for:\\nDesigning and develop machine learning algorithms, software utilities, tools, data sets, and experiments to build AI models.\\nBuilding solutions and delivering code from proof of concept to production-level maturity following agile development principles.\\nBreaking down and understanding complex business problems, defining a solution, and implementing it using advanced quantitative methods.\\nKeeping up to date with state-of-the-art machine learning literature and industry best practices for large-scale robust algorithm development.\\nDocumenting developments and results as needed for documentation, publications, patent submissions, and internal or external presentations.\\nCollaborating with cross-functional teams across multiple offices and regions. Also, Work alongside software developers and software engineers to translate algorithms into commercially viable products and services.\\nUnit-Testing for production quality code development and supporting end-to-end testing of delivered software components.\\nWorking in technical teams in development, deployment, and application of applied analytics, predictive analytics, and prescriptive analytics.\\nFuel your passion, To be successful in this role you will:\\nHave bachelors in Computer Science or STEM Majors (Science, Technology, Engineering and Math). A minimum 4 yrs of professional experience.\\nHave knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, and proper usage, etc.) and experience with applications.\\nExperience in Machine Learning/AI techniques including Deep learning (RNN, CNN, GAN, etc.), Support Vector Machines; Regularization Techniques; Boosting, Random Forests, Ensemble Methods, image/video/audio processing, Bayesian statistics, and time series modelling.\\nHave extensive applied experience with Reinforcement Learning is desired.\\nHave experience in developing and deploying machine learning solutions in cloud environments like AWS, Azure, and GCP.\\nHave developed containerized solutions (Docker, Mesos, etc.).\\nHave solid programming skills for data sciences and numerical computing: Python, R, and SQL and ability to work with a variety of deep learning frameworks including TensorFlow, Keras, Caffe, etc.\\nHave hands-on skills in sourcing, manipulating, and analysing large volumes of data including SQL and NoSQL databases.',\n",
       " 'Regarding opportunity with one of the clients of Gadiya Infosystems Pvt ltd\\n\\nRoles and Responsibilities\\nExperience level 5-9 Years of overall industrial experience\\nThe Data science contractor would be tasked with solving a real-life business problem that requires processing/analyzing\\nTBs of data and handling variety of data sources\\nThe work is organized as a project with clear deliverable and timeline\\nThe Data science contractor would collaborate with other team members who would provide support and mentoring\\nThe Data science contractor would proactively investigate, report, and where possible, address data quality issues\\nDesired Candidate Profile\\nExcellent in command of the English language\\nExperience with SQL, ideally Postgres\\nIntermediate knowledge of at least one programming language, ideally Python or R\\nGood understanding of statistical analysis and techniques: Classification analysis (Decision trees, Random forest, GBM,\\nLinear and Logistic regression analysis, ANOVA, Hypothesis testing, Cluster analysis, PCA)\\nPractical experience in data mining\\nExcellent knowledge of Excel\\nPreferred Skills:\\nGood understanding of API connections and data pipelining\\nUnderstanding of data engineering and data models\\nKnowledge with Natural Language Processing\\nUnderstanding of different model performance metrics and hyperparameters optimization\\nBusiness Acumen, ability to translate business needs into a set of workable, specific requirements',\n",
       " \"ROLES AND RESPONSIBILITIES:\\nParticipate in customer workshops to understand customer problems and design solutions with Advanced Analytics\\nDefine Advanced Analytics Use Cases and Implementation Roadmap\\nBuild Prototypes, POCs and Production ready Data Science applications\\nSupport and enhance Data Science Models/Applications\\nManage customer relationship and drive account growth initiatives\\nCollaborate with Partners for understanding the trends and new solutions and presenting the same to the customers and sales\\nSKILLS AND QUALIFICATIONS:\\nOverall, 10 to 12 yrs. of exp in solving customer problems with Data and 7-8 years of experience as Data Scientist for Life Sciences, Health Care and FMCG\\nDeep understanding and minimum 5 years of hands-on experience in developing models using Machine Learning and Deep Learning related technologies (such as Keras, TensorFlow, pyTorch, Azure ML, AWS ML, Jupiter, MATLAB, etc.)\\nStrong programming skills in one or more scripting languages like R, Python)\\nExperience with Data Visualization tools like Tableau, Microsoft Power BI and SiSense\\nExposure to working on AI/Data Science/Analytics platforms like SAS, Microsoft AI, Amazon AI, IBM WATSON, H20,\\nStrong business acumen to understand business objectives & dynamics and possess excellent written and verbal communication skills for coordinating across teams\\nExperience with common data science toolkits, such as Python, R, Weka, NumPy, MATLAB, etc\\nProficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification, tree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.\\nStrong hold of concepts in Statistics and expertise in Machine Logs Processing, text mining and text analytics\\nMaster's degree in Statistics, Applied Math, Operations Research, Economics, or a related quantitative field with working experience as a Data Scientist\",\n",
       " 'A. 10 - 12 years of Data experience with at least 5 yrs as Data scientist.\\nB. Lead a team of about 8 staff.\\nC. Python Data Science exp.\\nD. Data Modelling, Algorithms.\\nE. Knowledge of Databases to store and retrieve data.\\nF. Deep SQL & exp. doing EDA.\\n\\nRequired Candidate profile\\n1. SAS Enterprise Miner, SAS Base, SAS Model manager preferred.\\n2. Deep MS Excel knowledge.\\n3. Hands-on role.\\n4. Independent working with clients, provide insights in to their data and explain models.',\n",
       " 'Roles and Responsibilities\\nHiring for US based Start-up AI Fintech which is building Digital Banking platform for North American region.\\n\\nExperience for the Role : Data Scientist (1+ Yrs) & Senior/ Lead Data Scientist (3+ Yrs)\\n\\nLocation : Bangalore (HSR Layout)\\n\\nLooking expert machine learning and a statistical mastermind and who are keen to make a difference in a unique way.\\n\\nWe expect a Data Scientist & ML Engineer to take the onus of creating and leveraging the state-of-the-art algorithms in machine learning, deep learning and AI which will impact billions of people.\\n\\nMain Responsibilities :\\n\\nAs an ML Engineer / Data Scientist, you will work on cutting edge problems in Natural Language Processing using Deep Learning.\\n\\n- Perform exploratory data analysis to understand the problem\\n\\n- Implement and experiment with different features and architectures for Deep-Learning models for NLP\\n\\n- Do literature review and come up with possible solutions\\n\\n- Do visualisation for understanding the problem and showcasing models\\n\\n- Make the model faster for real-time predictions\\n\\n- Build tools to help the team build models and deploy them\\n\\nWhat We are looking:\\n\\n- B.Tech, M.Tech or Ph.D in Computer Science or equivalent work experience\\n\\n- Knowledgeable on common data structures and algorithms\\n\\n- Knowledgeable in one or more of the following : Machine Learning / Information Retrieval / Deep Learning / NLP\\n\\n- 1 to 5 year experience working with real world datasets\\n\\n- Strong interest in solving real world problems in Machine Learning\\n\\n- Programming experience (in any programming language) is a must\\n\\n- Good familiarity with Python and its scientific computing / ML ecosystem is preferable.',\n",
       " 'The Artificial Intelligence and Machine Learning (AIML) group at Fractal Analytics is actively involved in helping Fortune 500 companies by enabling them to discover how they can leverage their data using advanced and sophisticated AI/ML algorithms for which we are looking for Data Scientists with the capability to work on independent statistical and machine learning research/ projects. If you are a problem solver with a curiosity for exploring new techniques and technologies in AIML space, then we would like to talk with you.\\nJob Responsibilities\\nAbility to understand a problem statement and implement analytical solutions techniques independently with independently / proactively / thought-leadership.\\nWork with stakeholders throughout the organization to identify opportunities for leveraging company/client data to drive business solutions.\\nFast learner: ability to learn and pick up a new language/tool/ platform quickly.\\nConceptualize, design, and deliver high-quality solutions and insightful analysis.\\nConduct research and prototyping innovations; data and requirements gathering; solution scoping and architecture; consulting clients and client facing teams on advanced statistical and machine learning problems.\\nCollaborate and Coordinate with different functional teams(engineering and product development) to implement models and monitor outcomes.\\nAbility to deliver AIML based solutions around a host of domains and problems, with some of them being: Customer Segmentation Targeting, Propensity Modeling, Churn Modeling, Lifetime Value Estimation, Forecasting, Recommender Systems, Modeling Response to Incentives, Marketing Mix Optimization, Price Optimization\\nExperience Required:\\nExpert level proficiency in at least one of R and Python.\\nAbility to create efficient solutions to complex problems. Strong skills in data-structures and ML algorithms.\\nExperience of working on end-to-end data science pipeline: problem scoping, data gathering, EDA, modelling, insights, visualizations, monitoring and maintenance.\\nProblem-solving: Ability to break the problem into small parts and applying relevant techniques to drive required outcomes.\\nIntermediate to advanced knowledge of machine learning, probability theory, statistics, and algorithms. You will be required to discuss and use various algorithms and approaches on a daily basis.\\nWe use regression, Bayesian methods, tree-based learners, SVM, RF, XGBOOST, time series modeling, dimensionality reduction, SEM, GLM, GLMM, clustering, Deep learning etc. on a regular basis. If you know few of them you are good to go.\\nGood to Have:\\nExperience in one of the upcoming technologies like deep learning, NLP, image processing, recommender systems\\nExperience of working in on one or more domains:\\nCPG: pricing and promotion analytics, marketing analytics, trade promotions, supply chain management\\nBFSI: cross-sell, up-sell, campaign analytics, treasury analytics, fraud detection\\nHealthcare: medical adherence, medical risk profiling, EHR data, fraud-waste-abuse\\nExperience in working with Linux computing environment and use of command line tools like sed/awk\\nGood grasp on databases including RDBMS, NoSQL, MongoDB etc.\\nEducation Qualification\\nB.Tech / M.Tech in Computer Science / Mathematics / Signal Processing or related fields.',\n",
       " 'NA',\n",
       " 'Roles and Responsibilities\\nRequirements :\\n\\n- 6-9 years of strong experience in data mining, machine learning and statistical analysis.\\n\\n- BS/ MS/ PhD in Computer Science, Statistics, Applied Math, or related areas from Premier institutes ( only IITs / IISc / BITS / Top NITs or top US university should apply)\\n\\n- Ability to lead and deliver in a fast-paced start-up environment.\\n\\n- Fluency in tools such as Python/ R/ Matlab etc.\\n\\n- Strong intuition for data and Keen aptitude on large scale data analysis\\n\\n- Excellent written and verbal communication skills.\\n\\n- Ability to collaborate across teams and strong interpersonal skills.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For this task we have to scrap url for each job\n",
    "from selenium.common.exceptions import  NoSuchElementException\n",
    "url_job=[]\n",
    "for i in title:\n",
    "    url_job.append(i.get_attribute('href'))\n",
    "\n",
    "for k in url_job[0:10]:\n",
    "    try:\n",
    "        \n",
    "        driver.get(k)\n",
    "        descript=driver.find_element_by_xpath(\"//div[@class='dang-inner-html']\").text\n",
    "        desc.append(descript)\n",
    "    except NoSuchElementException:\n",
    "        desc.append('NA')\n",
    "\n",
    "desc=desc[:10]\n",
    "desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Finally create a dataframe of the scraped data.¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Job description\\n\\nJob Role: Data Scientist/Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Baker Hughes Incorporated</td>\n",
       "      <td>As as Senior Data Scientist, you will work in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Baker Hughes - The Network</td>\n",
       "      <td>As as Senior Data Scientist, you will work in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru(JP Nagar)</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>Regarding opportunity with one of the clients ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru(Dairy Circle)</td>\n",
       "      <td>ALTEN CALSOFT LABS (INDIA) PRIVATE LIMITED</td>\n",
       "      <td>ROLES AND RESPONSIBILITIES:\\nParticipate in cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru(Banashankari Stage II)</td>\n",
       "      <td>Pegasus Knowledge Solutions India Private Limited</td>\n",
       "      <td>A. 10 - 12 years of Data experience with at le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior/Lead Data Scientist - Machine Learning/...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Squareroot Consulting Pvt Ltd.</td>\n",
       "      <td>Roles and Responsibilities\\nHiring for US base...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>The Artificial Intelligence and Machine Learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru, Vadodara</td>\n",
       "      <td>Nielsen</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lead Data Scientist - Machine Learning/ Data M...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Roles and Responsibilities\\nRequirements :\\n\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Job  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                                  Sr Data Scientist   \n",
       "2                                  Sr Data Scientist   \n",
       "3                                     Data Scientist   \n",
       "4                                Lead Data Scientist   \n",
       "5                              Senior Data Scientist   \n",
       "6  Senior/Lead Data Scientist - Machine Learning/...   \n",
       "7                              Senior Data Scientist   \n",
       "8                              Senior Data Scientist   \n",
       "9  Lead Data Scientist - Machine Learning/ Data M...   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                      Bangalore/Bengaluru(JP Nagar)   \n",
       "4                  Bangalore/Bengaluru(Dairy Circle)   \n",
       "5         Bangalore/Bengaluru(Banashankari Stage II)   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7      Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "8             Chennai, Bangalore/Bengaluru, Vadodara   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                             Company  \\\n",
       "0                 Inflexion Analytix Private Limited   \n",
       "1                          Baker Hughes Incorporated   \n",
       "2                         Baker Hughes - The Network   \n",
       "3                                       Confidential   \n",
       "4         ALTEN CALSOFT LABS (INDIA) PRIVATE LIMITED   \n",
       "5  Pegasus Knowledge Solutions India Private Limited   \n",
       "6                     Squareroot Consulting Pvt Ltd.   \n",
       "7                                  Fractal Analytics   \n",
       "8                                            Nielsen   \n",
       "9                       Wrackle Technologies Pvt Ltd   \n",
       "\n",
       "                                     Job Description  \n",
       "0  Job description\\n\\nJob Role: Data Scientist/Da...  \n",
       "1  As as Senior Data Scientist, you will work in ...  \n",
       "2  As as Senior Data Scientist, you will work in ...  \n",
       "3  Regarding opportunity with one of the clients ...  \n",
       "4  ROLES AND RESPONSIBILITIES:\\nParticipate in cu...  \n",
       "5  A. 10 - 12 years of Data experience with at le...  \n",
       "6  Roles and Responsibilities\\nHiring for US base...  \n",
       "7  The Artificial Intelligence and Machine Learni...  \n",
       "8                                                 NA  \n",
       "9  Roles and Responsibilities\\nRequirements :\\n\\n...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_Scientist={'Job':job,'Location':loc,\n",
    "              'Company':comp,'Job Description':desc}\n",
    "Data_Scientist=pd.DataFrame(data=Data_Scientist)\n",
    "Data_Scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: In this question you have to scrape data using the filters available on the webpage as shown below:¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### You have to use the location and salary filter. You have to scrape data for “Data Scientist” designation for first 10 job results. You have to scrape the job-title, job-location, company_name, experience_required. The location filter to be used is “Delhi/NCR” The salary filter to be used is “3-6” lakhs The task will be done as shown in the below steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The task will be done as shown in the below steps:¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. First get the webpage https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. Enter “Data Scientist” in “Skill,Designations,Companies” field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//input[@class='sugInp']\").send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Then click the search button.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//button[@class='btn']\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Then apply the location filter and salary filter by checking the respective boxes¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying filter for location 'Delhi/NCR'\n",
    "\n",
    "driver.find_element_by_xpath(\"//label[@for='chk-Delhi / NCR-cityTypeGid-']/i\").click()\n",
    "time.sleep(4)\n",
    "\n",
    "#Applying fliter for salary '3-6 lakhs'\n",
    "\n",
    "driver.find_element_by_xpath(\"//label[@for='chk-3-6 Lakhs-ctcFilter-']/i\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Then scrape the data for the first 10 jobs results you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist/Data Analyst /Business Analyst</td>\n",
       "      <td>Pune, Delhi / NCR, Mumbai (All Areas)</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>Noida, Greater Noida, Delhi / NCR</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Machine Learning/ NLP</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>TalPro</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist || Python || C2H</td>\n",
       "      <td>Noida, Kolkata, Gurgaon/Gurugram, Bangalore/Be...</td>\n",
       "      <td>Growel Softech Pvt. Ltd.</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist || Python || C2H</td>\n",
       "      <td>Noida, Kolkata, Gurgaon/Gurugram, Bangalore/Be...</td>\n",
       "      <td>Growel Softech Pvt. Ltd.</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Advanced Analytics -Data Scientist</td>\n",
       "      <td>New Delhi, Hyderabad/Secunderabad</td>\n",
       "      <td>ERM Placement Services (P) Ltd.</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Text NLP | Noida</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Acidaes Solutions Pvt. Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist (Early Joiner)</td>\n",
       "      <td>Noida(Sector-59 Noida)</td>\n",
       "      <td>R Systems International Ltd.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Machine Learning/NLP</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>TalPro</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data analytics / Data scientist intern (work f...</td>\n",
       "      <td>Kolkata, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>TalkValley LLC</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Job  \\\n",
       "0      Data Scientist/Data Analyst /Business Analyst   \n",
       "1  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "2             Data Scientist - Machine Learning/ NLP   \n",
       "3                    Data Scientist || Python || C2H   \n",
       "4                    Data Scientist || Python || C2H   \n",
       "5                 Advanced Analytics -Data Scientist   \n",
       "6                  Data Scientist - Text NLP | Noida   \n",
       "7                      Data Scientist (Early Joiner)   \n",
       "8              Data Scientist - Machine Learning/NLP   \n",
       "9  Data analytics / Data scientist intern (work f...   \n",
       "\n",
       "                                            Location  \\\n",
       "0              Pune, Delhi / NCR, Mumbai (All Areas)   \n",
       "1                  Noida, Greater Noida, Delhi / NCR   \n",
       "2                                   Gurgaon/Gurugram   \n",
       "3  Noida, Kolkata, Gurgaon/Gurugram, Bangalore/Be...   \n",
       "4  Noida, Kolkata, Gurgaon/Gurugram, Bangalore/Be...   \n",
       "5                  New Delhi, Hyderabad/Secunderabad   \n",
       "6                                              Noida   \n",
       "7                             Noida(Sector-59 Noida)   \n",
       "8                                   Gurgaon/Gurugram   \n",
       "9          Kolkata, Bangalore/Bengaluru, Delhi / NCR   \n",
       "\n",
       "                              Company Experience  \n",
       "0  Inflexion Analytix Private Limited    0-3 Yrs  \n",
       "1           GABA Consultancy services    0-0 Yrs  \n",
       "2                              TalPro    2-6 Yrs  \n",
       "3            Growel Softech Pvt. Ltd.    4-6 Yrs  \n",
       "4            Growel Softech Pvt. Ltd.    4-6 Yrs  \n",
       "5     ERM Placement Services (P) Ltd.    3-7 Yrs  \n",
       "6         Acidaes Solutions Pvt. Ltd.    3-5 Yrs  \n",
       "7        R Systems International Ltd.    4-8 Yrs  \n",
       "8                              TalPro    2-6 Yrs  \n",
       "9                      TalkValley LLC    0-5 Yrs  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# We will create empty list in which we will update the required data\n",
    "Job=[]\n",
    "Loc=[]\n",
    "Comp=[]\n",
    "Exp=[]\n",
    "\n",
    "#scrapping job titles\n",
    "titles = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    Job.append(i.text)\n",
    "    Job=Job[:10]\n",
    "    \n",
    "#scrapping location\n",
    "loct=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "for i in loct:\n",
    "    Loc.append(i.text)\n",
    "    Loc=Loc[:10]\n",
    "    \n",
    "#scrapping company\n",
    "comp=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in comp:\n",
    "    Comp.append(i.text)\n",
    "    Comp=Comp[:10]\n",
    "    \n",
    "#scrapping experience\n",
    "expe=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "for i in expe:\n",
    "    Exp.append(i.text)\n",
    "    Exp=Exp[:10]\n",
    "\n",
    "#Creating the DataFrame\n",
    "Data_Scientist_Delhi={'Job':Job,'Location':Loc,\n",
    "              'Company':Comp,'Experience':Exp}\n",
    "Data_Scientist_Delhi=pd.DataFrame(data=Data_Scientist_Delhi)\n",
    "Data_Scientist_Delhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### This task will be done in following steps:¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. first get the webpage https://www.glassdoor.co.in/index.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.glassdoor.co.in/index.htm'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” in “location” field.¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "#Entering Data Scientist in Job field\n",
    "driver.find_element_by_xpath(\"//input[@id='sc.keyword']\").send_keys('Data Scientist')\n",
    "\n",
    "#To ender 'Noida' in loaction field, I have to delete 'Mumbai' which is auto populated.\n",
    "driver.find_element_by_xpath('//input[@id=\"sc.location\"]').clear()\n",
    "driver.find_element_by_xpath('//*[@id=\"sc.location\"]').send_keys('Noida')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Then click the search button.¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\").click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Then scrape the data for the first 10 jobs results you get in the above shown page.¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Days Posted</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PayPal</td>\n",
       "      <td>14d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PayPal</td>\n",
       "      <td>14d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Olam Group</td>\n",
       "      <td>3d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Citi</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baker Hughes</td>\n",
       "      <td>3d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FE Fundinfo</td>\n",
       "      <td>20d</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Standard Chartered</td>\n",
       "      <td>19d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Aspire Systems</td>\n",
       "      <td>6d</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Springer Nature</td>\n",
       "      <td>11d</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VM3 Tech Solutions</td>\n",
       "      <td>13d</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Company Name Days Posted Rating\n",
       "0              PayPal         14d    4.3\n",
       "1              PayPal         14d    4.3\n",
       "2          Olam Group          3d    3.8\n",
       "3                Citi                   \n",
       "4        Baker Hughes          3d    3.7\n",
       "5         FE Fundinfo         20d    4.5\n",
       "6  Standard Chartered         19d    3.8\n",
       "7      Aspire Systems          6d    4.0\n",
       "8     Springer Nature         11d    3.6\n",
       "9  VM3 Tech Solutions         13d    5.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will create empty list in which we will update the required data\n",
    "c_name=[]\n",
    "days=[]\n",
    "rating=[]\n",
    "\n",
    "#scrapping company name\n",
    "companies=driver.find_elements_by_xpath(\"//a[@class=' css-l2wjgv e1n63ojh0 jobLink']\")\n",
    "for i in companies:\n",
    "    c_name.append(i.text)\n",
    "    c_name=c_name[:10]\n",
    "\n",
    "#scrapping the number of days before it was posted\n",
    "day=driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\")\n",
    "for i in day:\n",
    "    days.append(i.text)\n",
    "    days=days[:10]\n",
    "\n",
    "ratings=driver.find_elements_by_xpath(\"//div[@class='d-flex flex-column css-x75kgh e1rrn5ka3']\")\n",
    "for i in ratings:\n",
    "    rating.append(i.text)\n",
    "    rating=rating[:10]\n",
    "    \n",
    "#Creating the DataFrame\n",
    "\n",
    "DS_Glassdoor={'Company Name':c_name,'Days Posted':days,'Rating':rating}\n",
    "DS_Glassdoor=pd.DataFrame(data=DS_Glassdoor)\n",
    "DS_Glassdoor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above task will be, done as shown in the below steps:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "\n",
    " \n",
    "time.sleep(2)\n",
    "\n",
    "driver.get('https://www.glassdoor.co.in/Salaries/index.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "\n",
    "driver.find_element_by_xpath(\"//input[@name='sc.keyword']\").send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//input[@id='LocationSearch']\").clear()\n",
    "driver.find_element_by_xpath(\"//input[@id='LocationSearch']\").send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//button[@class='gd-btn-mkt']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company name</th>\n",
       "      <th>Number of salaries</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Min Salary</th>\n",
       "      <th>Max Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Company name, Number of salaries, Average Salary, Min Salary, Max Salary]\n",
       "Index: []"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=[]\n",
    "mins=[]\n",
    "maxs=[]\n",
    "avg=[]\n",
    "num=[]\n",
    "\n",
    "#scrapping company name\n",
    "for i in driver.find_elements_by_xpath(\"//p[@class='m-0 ']\"):\n",
    "    c.append(i.text)\n",
    "    c=c[:10]\n",
    "\n",
    "#scrapping min salary\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']/span[1]\"):\n",
    "    mins.append(i.text)\n",
    "    mins=mins[:10]\n",
    "\n",
    "#scrapping max salary\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']/span[2]\"):\n",
    "    maxs.append(i.text)\n",
    "    maxs=maxs[:10]\n",
    "    \n",
    "#scrapping average salary    \n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']\"):\n",
    "    avg.append(i.text.replace('\\n',''))\n",
    "    avg=avg[:10]\n",
    "\n",
    "#scrapping number of salaries\n",
    "for i in driver.find_elements_by_xpath(\"//p[@class='css-1uyte9r css-1kuy7z7 m-0 ']\"):\n",
    "    num.append(i.text)\n",
    "    num=num[:10]\n",
    "    \n",
    "#creating a dataframe for #Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "\n",
    "DS_Sal={'Company name':c,'Number of salaries':num,'Average Salary':avg,\n",
    "       'Min Salary':mins,'Max Salary':maxs}\n",
    "DS_Sal=pd.DataFrame(data=DS_Sal)\n",
    "DS_Sal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Brand\n",
    "2.Product Description\n",
    "3.Price\n",
    "4.Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once the website opens we get the pop. To cancel the pop up\n",
    "driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon.\n",
    "\n",
    "driver.find_element_by_xpath(\"//input[@class='_3704LK']\").send_keys('sunglasses')\n",
    "driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 3. after that you will reach to a webpage having a lot of sunglasses. \n",
    "#From this page you can scrap the required data as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart UV Protection Wayfarer Sunglasses ...</td>\n",
       "      <td>₹1,120</td>\n",
       "      <td>₹879 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection, Gradient, Night Vision, Mirrore...</td>\n",
       "      <td>₹365</td>\n",
       "      <td>₹810 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹299</td>\n",
       "      <td>₹2300 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹682</td>\n",
       "      <td>₹217 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection, Polarized Wayfarer Sunglasses (56)</td>\n",
       "      <td>₹529</td>\n",
       "      <td>₹370 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Wrap-around Sunglasses (Free Size)</td>\n",
       "      <td>₹664</td>\n",
       "      <td>₹835 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹529</td>\n",
       "      <td>₹370 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>₹300 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Shield Sunglasses (54)</td>\n",
       "      <td>₹592</td>\n",
       "      <td>₹307 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>₹2056 off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                        Description   Price  \\\n",
       "0    VINCENT CHASE  by Lenskart UV Protection Wayfarer Sunglasses ...  ₹1,120   \n",
       "1            NuVew  UV Protection, Gradient, Night Vision, Mirrore...    ₹365   \n",
       "2   kingsunglasses  Mirrored, UV Protection Wayfarer Sunglasses (F...    ₹299   \n",
       "3         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹682   \n",
       "4         Fastrack  UV Protection, Polarized Wayfarer Sunglasses (56)    ₹529   \n",
       "..             ...                                                ...     ...   \n",
       "95       ROYAL SON   UV Protection Wrap-around Sunglasses (Free Size)    ₹664   \n",
       "96        Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹529   \n",
       "97        Fastrack       UV Protection Aviator Sunglasses (Free Size)    ₹499   \n",
       "98        Fastrack               UV Protection Shield Sunglasses (54)    ₹592   \n",
       "99  ROZZETTA CRAFT              UV Protection Aviator Sunglasses (57)    ₹499   \n",
       "\n",
       "     Discount  \n",
       "0    ₹879 off  \n",
       "1    ₹810 off  \n",
       "2   ₹2300 off  \n",
       "3    ₹217 off  \n",
       "4    ₹370 off  \n",
       "..        ...  \n",
       "95   ₹835 off  \n",
       "96   ₹370 off  \n",
       "97   ₹300 off  \n",
       "98   ₹307 off  \n",
       "99  ₹2056 off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "\n",
    "b=[]\n",
    "pdis=[]\n",
    "pr=[]\n",
    "dis=[]\n",
    "\n",
    "#scrapping the brand name\n",
    "for i in range(0,3):\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\"):\n",
    "        b.append(j.text)\n",
    "        b=b[:100]\n",
    "        \n",
    "#scrapping the product description\n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "        pdis.append(j.text)\n",
    "        pdis=pdis[:100]\n",
    "\n",
    "#scrapping the product price\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\"):\n",
    "        pr.append(j.text)\n",
    "        pr=pr[:100]\n",
    "\n",
    "#scrapping the product discount\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\"):\n",
    "        dis.append(j.text)\n",
    "        dis=dis[:100]\n",
    "\n",
    "#clicking on the next page\n",
    "    driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\").click()\n",
    "    time.sleep(2)\n",
    "\n",
    "#creating the dataframe\n",
    "Flipkart_Sun={'Brand':b,'Description':pdis,'Price':pr,'Discount':dis}\n",
    "Flipkart_Sun=pd.DataFrame(data=Flipkart_Sun)\n",
    "Flipkart_Sun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As shown in the above page you have to scrape the tick marked attributes.¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are\n",
    "\n",
    "Rating\n",
    "Review_summary\n",
    "Full review You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2)\n",
    "\n",
    "#1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#clicking on all reviews\n",
    "\n",
    "driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating      Review Summary  \\\n",
       "0       5           Brilliant   \n",
       "1       5    Perfect product!   \n",
       "2       5   Worth every penny   \n",
       "3       5           Fabulous!   \n",
       "4       5       Great product   \n",
       "..    ...                 ...   \n",
       "95      5      Simply awesome   \n",
       "96      4         Good choice   \n",
       "97      5   Worth every penny   \n",
       "98      5  Highly recommended   \n",
       "99      5    Perfect product!   \n",
       "\n",
       "                                          Full Review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Previously I was using one plus 3t it was a gr...  \n",
       "3   This is my first iOS phone. I am very happy wi...  \n",
       "4   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "..                                                ...  \n",
       "95  Really satisfied with the Product I received.....  \n",
       "96  So far it’s been an AMAZING experience coming ...  \n",
       "97  i11 is worthy to buy, too much happy with the ...  \n",
       "98  iphone 11 is a very good phone to buy only if ...  \n",
       "99  It’s a must buy who is looking for an upgrade ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the empty list to store the data\n",
    "\n",
    "rating=[]\n",
    "summ=[]\n",
    "full=[]\n",
    "\n",
    "for i in range(0,11):\n",
    "    \n",
    "    #scrapping the rating\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\"):\n",
    "        rating.append(j.text)\n",
    "        rating=rating[:100]\n",
    "    \n",
    "    #scrapping the sunn\n",
    "    for j in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "        summ.append(j.text)\n",
    "        summ=summ[:100]\n",
    "\n",
    "    #scrapping the full review\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\"):\n",
    "        full.append(j.text)\n",
    "        full=full[:100]\n",
    "\n",
    "#creating the dataframe\n",
    "iphone_reviews={'Rating':rating,'Review Summary':summ,'Full Review':full}\n",
    "iphone_reviews=pd.DataFrame(data=iphone_reviews)\n",
    "iphone_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to scrape 4 attributes of each sneaker :\n",
    "\n",
    "Brand\n",
    "Product Description\n",
    "Price\n",
    "discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2)\n",
    "\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//input[@class='_3704LK']\").send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "productdis=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "#scrapping the brand name\n",
    "for i in range(0,4):\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\"):\n",
    "        brand.append(j.text)\n",
    "        brand=brand[:100]\n",
    "        \n",
    "#scrapping the product description\n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "        productdis.append(j.text)\n",
    "        productdis=productdis[:100]\n",
    "\n",
    "#scrapping the product price\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\"):\n",
    "        price.append(j.text)\n",
    "        price=price[:100]\n",
    "\n",
    "#scrapping the product discount\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\"):\n",
    "        discount.append(j.text)\n",
    "        discount=discount[:100]\n",
    "\n",
    "#clicking on the next page\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\").click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\").click()\n",
    "            \n",
    "#creating the dataframe\n",
    "Flipkart_Sneakers={'Brand':brand,'Description':productdis,'Price':price,'Discount':discount}\n",
    "Flipkart_Sneakers=pd.DataFrame(data=Flipkart_Sneakers)\n",
    "Flipkart_Sneakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Q9: Go to the link - myntra.com/shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”,\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe as shown in the below image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2)\n",
    "\n",
    "driver.get('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#price filter (there is no price filter for 6649 to 13099 hence will filter it with 6612 to 13075)\n",
    "\n",
    "driver.find_element_by_xpath(\"//ul[@class='price-list']/li[2]\").click()\n",
    "time.sleep(2)\n",
    "\n",
    "#color filter\n",
    "driver.find_element_by_xpath(\"//span[@data-colorhex='black']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Sneakers</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR ZOOM Running Shoes</td>\n",
       "      <td>Rs. 8236Rs. 10295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Unisex LEBRON XVIII Basketball</td>\n",
       "      <td>Rs. 12316Rs. 17595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Unisex COSMIC UNITY Basketball</td>\n",
       "      <td>Rs. 13495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Zoom Winflo 8 Running</td>\n",
       "      <td>Rs. 8295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROSSO BRUNELLO</td>\n",
       "      <td>Men Solid Leather Formal Monks</td>\n",
       "      <td>Rs. 13499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Kenneth Cole</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>Rs. 8154Rs. 13590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Birkenstock</td>\n",
       "      <td>Women Marillia Natural Leather Flats</td>\n",
       "      <td>Rs. 13490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Birkenstock</td>\n",
       "      <td>Women Arizona Oiled Leather Flats</td>\n",
       "      <td>Rs. 11990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Birkenstock</td>\n",
       "      <td>Women Derbys Casual Shoes</td>\n",
       "      <td>Rs. 11990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                           Description               Price\n",
       "0             ALDO                          Men Sneakers            Rs. 9999\n",
       "1             Nike            Men AIR ZOOM Running Shoes   Rs. 8236Rs. 10295\n",
       "2             Nike        Unisex LEBRON XVIII Basketball  Rs. 12316Rs. 17595\n",
       "3             Nike        Unisex COSMIC UNITY Basketball           Rs. 13495\n",
       "4             Nike             Men Zoom Winflo 8 Running            Rs. 8295\n",
       "..             ...                                   ...                 ...\n",
       "95  ROSSO BRUNELLO        Men Solid Leather Formal Monks           Rs. 13499\n",
       "96    Kenneth Cole       Men Solid Leather Formal Derbys   Rs. 8154Rs. 13590\n",
       "97     Birkenstock  Women Marillia Natural Leather Flats           Rs. 13490\n",
       "98     Birkenstock     Women Arizona Oiled Leather Flats           Rs. 11990\n",
       "99     Birkenstock             Women Derbys Casual Shoes           Rs. 11990\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the dataframe to store the data\n",
    "shoe=[]\n",
    "ssdesc=[]\n",
    "shoeprice=[]\n",
    "\n",
    "for i in range(0,2):\n",
    "    time.sleep(2)\n",
    "    for i in driver.find_elements_by_xpath(\"//h3[@class='product-brand']\"):\n",
    "        shoe.append(i.text)\n",
    "        shoe=shoe[:100]\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//h4[@class='product-product']\"):\n",
    "        ssdesc.append(i.text)\n",
    "        ssdesc=ssdesc[:100]\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='product-price']/span[1]\"):\n",
    "        shoeprice.append(i.text)\n",
    "        shoeprice=shoeprice[:100]\n",
    "        \n",
    "    #going to the next page\n",
    "    driver.find_element_by_xpath(\"//a[@rel='next']\").click()\n",
    "    \n",
    "#creating the dataframe\n",
    "Myntra_Shoes={'Brand':shoe,'Description':ssdesc,'Price':shoeprice}\n",
    "Myntra_Shoes=pd.DataFrame(data=Myntra_Shoes)\n",
    "Myntra_Shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Q10: Go to webpage https://www.amazon.in/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2)\n",
    "\n",
    "driver.get(' https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Entering the laptop under search\n",
    "driver.find_element_by_xpath('//input[@id=\"twotabsearchtextbox\"]').send_keys('Laptop')\n",
    "time.sleep(2)\n",
    "\n",
    "#clicking the search button\n",
    "\n",
    "driver.find_element_by_xpath('//input[@id=\"nav-search-submit-button\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the filter for “Intel Core i7” and “Intel Core i9” \n",
    "\n",
    "driver.find_element_by_xpath(\"//*[@id='p_n_feature_thirteen_browse-bin/12598163031']/span/a\").click()\n",
    "time.sleep(4)\n",
    "\n",
    "driver.find_element_by_xpath(\"//*[@id='p_n_feature_thirteen_browse-bin/16757432031']/span/a\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:¶\n",
    "title\n",
    "Ratings\n",
    "Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>59,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>78,993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Renewed) Dell Intel Core i7 4th Gen 14 Inch(3...</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>46,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSI GF65 Thin 10SDR 15.6\" FHD Gaming Laptop - ...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>97,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Renewed) Dell Intel Core i7 4th Gen 14 Inch(3...</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "      <td>39,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dell Inspiron 5410 14\" FHD Touch Display 2in1 ...</td>\n",
       "      <td>3.7 out of 5 stars</td>\n",
       "      <td>91,790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Pavilion Gaming 10th Gen Intel Core i7 Proc...</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP 14 Thin &amp; Light 14\" (35.56cms) FHD Laptop (...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>88,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Renewed) Dell Intel Core i7 4th Gen 14 Inch(3...</td>\n",
       "      <td>2.9 out of 5 stars</td>\n",
       "      <td>42,999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title             Ratings  \\\n",
       "0  HP Pavilion (2021) Thin & Light 11th Gen Core ...  4.5 out of 5 stars   \n",
       "1  Mi Notebook Horizon Edition 14 Intel Core i7-1...  4.4 out of 5 stars   \n",
       "2  HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...  3.9 out of 5 stars   \n",
       "3  (Renewed) Dell Intel Core i7 4th Gen 14 Inch(3...  4.5 out of 5 stars   \n",
       "4  MSI GF65 Thin 10SDR 15.6\" FHD Gaming Laptop - ...  4.2 out of 5 stars   \n",
       "5  (Renewed) Dell Intel Core i7 4th Gen 14 Inch(3...  4.6 out of 5 stars   \n",
       "6  Dell Inspiron 5410 14\" FHD Touch Display 2in1 ...  3.7 out of 5 stars   \n",
       "7  HP Pavilion Gaming 10th Gen Intel Core i7 Proc...  4.4 out of 5 stars   \n",
       "8  HP 14 Thin & Light 14\" (35.56cms) FHD Laptop (...  4.1 out of 5 stars   \n",
       "9  (Renewed) Dell Intel Core i7 4th Gen 14 Inch(3...  2.9 out of 5 stars   \n",
       "\n",
       "    Price  \n",
       "0  84,990  \n",
       "1  59,999  \n",
       "2  78,993  \n",
       "3  46,999  \n",
       "4  97,999  \n",
       "5  39,999  \n",
       "6  91,790  \n",
       "7  86,990  \n",
       "8  88,990  \n",
       "9  42,999  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrapping the data\n",
    "\n",
    "#creating the empty list to enter the data\n",
    "Title=[]\n",
    "Ratings=[]\n",
    "Price=[]\n",
    "\n",
    "#scrapping the title\n",
    "for i in driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-normal\"]'):\n",
    "    Title.append(i.text)\n",
    "    Title=Title[:10]\n",
    "\n",
    "#scrapping the rating\n",
    "\n",
    "Rating=driver.find_elements_by_xpath('//div[@class=\"a-row a-size-small\"]/span[1]')  \n",
    "for i in Rating:\n",
    "    Ratings.append(i.get_attribute('aria-label'))\n",
    "    Ratings=Ratings[:10]\n",
    "    \n",
    "#scrapping the Price\n",
    "for i in driver.find_elements_by_xpath('//span[@class=\"a-price-whole\"]'):\n",
    "    Price.append(i.text)\n",
    "    Price=Price[:10]\n",
    "    \n",
    "#creating the dataframe\n",
    "Amazon_laptop={'Title':Title,'Ratings':Ratings,'Price':Price}\n",
    "Amazon_laptop=pd.DataFrame(data=Amazon_laptop)\n",
    "Amazon_laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
